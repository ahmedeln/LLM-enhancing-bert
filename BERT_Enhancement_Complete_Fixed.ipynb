{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50bf9344",
   "metadata": {},
   "source": [
    "# BERT Enhancement Analysis: Before & After\n",
    "\n",
    "**Four Key Enhancements:**\n",
    "1. Embedding Factorization (768→128): 83% reduction\n",
    "2. Windowed Attention (size=8): 87-97% faster\n",
    "3. SwiGLU Activation: Better gradients\n",
    "4. Parameter Sharing: 92% reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91303e1b",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "212b33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 5)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73f8e16",
   "metadata": {},
   "source": [
    "## 2. Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e238033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_config = {\n",
    "    'hidden_size': 768,\n",
    "    'num_hidden_layers': 12,\n",
    "    'num_attention_heads': 12,\n",
    "    'intermediate_size': 3072,\n",
    "    'hidden_act': 'gelu',\n",
    "    'vocab_size': 30522,\n",
    "    'max_position_embeddings': 512,\n",
    "    'type_vocab_size': 2\n",
    "}\n",
    "\n",
    "enhanced_config = original_config.copy()\n",
    "enhanced_config.update({\n",
    "    'embedding_size': 128,\n",
    "    'window_size': 8,\n",
    "    'use_swiglu': True,\n",
    "    'share_parameters': True,\n",
    "    'num_hidden_layers': 1\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c9d457",
   "metadata": {},
   "source": [
    "## 3. Parameter Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2e593b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Component                      Original             Enhanced             Reduction %         \n",
      "Token Embeddings                         23,440,896            3,906,816                83.3%\n",
      "Position Embeddings                         393,216               65,536                83.3%\n",
      "Type Embeddings                               1,536                  256                83.3%\n",
      "Embedding LayerNorm                             768                  768                 0.0%\n",
      "Transformer Layers                      113,402,880           11,812,608                89.6%\n",
      "Pooler                                      590,592              590,592                 0.0%\n",
      "Classification Head                           1,538                1,538                 0.0%\n",
      "TOTAL                                   137,831,426           16,476,418                     \n"
     ]
    }
   ],
   "source": [
    "def calculate_model_parameters(config):\n",
    "    params = OrderedDict()\n",
    "    \n",
    "    vocab_size = config['vocab_size']\n",
    "    hidden_size = config['hidden_size']\n",
    "    embedding_size = config.get('embedding_size', hidden_size)\n",
    "    num_layers = config['num_hidden_layers']\n",
    "    intermediate_size = config['intermediate_size']\n",
    "    use_swiglu = config.get('use_swiglu', False)\n",
    "    share_params = config.get('share_parameters', False)\n",
    "    \n",
    "    params['Token Embeddings'] = vocab_size * embedding_size\n",
    "    params['Position Embeddings'] = 512 * embedding_size\n",
    "    params['Type Embeddings'] = 2 * embedding_size\n",
    "    \n",
    "    if embedding_size != hidden_size:\n",
    "        params['Embedding Projection'] = embedding_size * hidden_size\n",
    "    \n",
    "    params['Embedding LayerNorm'] = hidden_size\n",
    "    \n",
    "    attention_params = hidden_size * hidden_size * 3 + hidden_size * 3\n",
    "    attention_params += hidden_size * hidden_size + hidden_size\n",
    "    attention_params += hidden_size * 2\n",
    "    \n",
    "    ffn_multiplier = 3 if use_swiglu else 2\n",
    "    ffn_params = hidden_size * intermediate_size * ffn_multiplier + intermediate_size * ffn_multiplier\n",
    "    ffn_params += hidden_size * intermediate_size + hidden_size\n",
    "    ffn_params += hidden_size * 2\n",
    "    \n",
    "    layer_params = attention_params + ffn_params\n",
    "    \n",
    "    if share_params:\n",
    "        params['Transformer Layers'] = layer_params  # Mark as shared in output\n",
    "    else:\n",
    "        params['Transformer Layers'] = layer_params * num_layers\n",
    "    \n",
    "    params['Pooler'] = hidden_size * hidden_size + hidden_size\n",
    "    params['Classification Head'] = hidden_size * 2 + 2\n",
    "    params['TOTAL'] = sum(params.values())\n",
    "    \n",
    "    return params\n",
    "\n",
    "orig_params = calculate_model_parameters(original_config)\n",
    "enh_params = calculate_model_parameters(enhanced_config)\n",
    "\n",
    "print(f\"\\n{'Component':<30} {'Original':<20} {'Enhanced':<20} {'Reduction %':<20}\")\n",
    "\n",
    "for key in orig_params.keys():\n",
    "    \n",
    "    orig_count = orig_params[key]\n",
    "    enh_count = enh_params[key]\n",
    "    reduction = ((orig_count - enh_count) / orig_count) * 100 if orig_count > 0 else 0\n",
    "    \n",
    "    orig_str = f\"{orig_count:,.0f}\" if orig_count >= 1 else f\"{orig_count:.4f}\"\n",
    "    enh_str = f\"{enh_count:,.0f}\" if enh_count >= 1 else f\"{enh_count:.4f}\"\n",
    "    reduction_str = f\"{reduction:.1f}%\" if key != 'TOTAL' else \"\"\n",
    "    \n",
    "    print(f\"{key:<30} {orig_str:>20} {enh_str:>20} {reduction_str:>20}\")\n",
    "\n",
    "overall_reduction = ((orig_params['TOTAL'] - enh_params['TOTAL']) / orig_params['TOTAL']) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7125f77",
   "metadata": {},
   "source": [
    "## 6. Code Implementation: Before & After"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bd2f2d",
   "metadata": {},
   "source": [
    "### Enhancement #1: Embedding Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "49935e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding Factorization:\n",
      "- Reduce embedding 768 → 128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Embedding Factorization:\n",
    "- Reduce embedding 768 → 128\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b93ea97",
   "metadata": {},
   "source": [
    "### Enhancement #2: Windowed Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "526312a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Windowed Attention:\n",
      "- Local attention window = 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Windowed Attention:\n",
    "- Local attention window = 8\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b123191",
   "metadata": {},
   "source": [
    "### Enhancement #3: SwiGLU Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "37ddcefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SwiGLU Activation:\n",
      "- Replace GELU with Swish + GLU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "SwiGLU Activation:\n",
    "- Replace GELU with Swish + GLU\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01623682",
   "metadata": {},
   "source": [
    "### Enhancement #4: Parameter Sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ecd133e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameter Sharing:\n",
      "- Use 1 shared layer instead of 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Parameter Sharing:\n",
    "- Use 1 shared layer instead of 12\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b845dbf4",
   "metadata": {},
   "source": [
    "## 7. Feature Extraction: Original Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7407d9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "  Text: 'This sample text is public domain and was randomly selected from Proje...'\n",
      "  Tokens: 15\n",
      "  Feature dimension: 768\n",
      "  Output shape: (15, 768)\n",
      "  Memory per sample: 45.00 KB\n",
      "\n",
      "Example 2:\n",
      "  Text: 'The rain had only ceased with the gray streaks of morning at Blazing S...'\n",
      "  Tokens: 54\n",
      "  Feature dimension: 768\n",
      "  Output shape: (54, 768)\n",
      "  Memory per sample: 162.00 KB\n",
      "\n",
      "Example 3:\n",
      "  Text: 'Indeed, it was recorded in Blazing Star that a fortunate early riser h...'\n",
      "  Tokens: 43\n",
      "  Feature dimension: 768\n",
      "  Output shape: (43, 768)\n",
      "  Memory per sample: 129.00 KB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('bert/sample_text.txt', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "lines = [line.strip() for line in content.split('\\n') if line.strip() and not line.startswith('Text should')]\n",
    "sample_text = [line for line in lines if len(line) > 50][:3]\n",
    "\n",
    "\n",
    "extraction_data_original = []\n",
    "for i, text in enumerate(sample_text, 1):\n",
    "    tokens = ['[CLS]'] + text.split() + ['[SEP]']\n",
    "    num_tokens = len(tokens)\n",
    "    feature_size = original_config['hidden_size']\n",
    "    output_shape = (num_tokens, feature_size)\n",
    "    \n",
    "    print(f\"Example {i}:\")\n",
    "    print(f\"  Text: '{text[:70]}...'\")\n",
    "    print(f\"  Tokens: {num_tokens}\")\n",
    "    print(f\"  Feature dimension: {feature_size}\")\n",
    "    print(f\"  Output shape: {output_shape}\")\n",
    "    print(f\"  Memory per sample: {num_tokens * feature_size * 4 / 1024:.2f} KB\")\n",
    "    \n",
    "    extraction_data_original.append({\n",
    "        'example': i,\n",
    "        'num_tokens': num_tokens,\n",
    "        'feature_dim': feature_size,\n",
    "        'memory_kb': num_tokens * feature_size * 4 / 1024\n",
    "    })\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0d19ca",
   "metadata": {},
   "source": [
    "**To run code in extract_features.py use this command in the terminal:**\n",
    "\n",
    "python extract_features.py `\n",
    "  --input_file=\"sample_text.txt\" `\n",
    "  --output_file=\"features_demo.jsonl\" `\n",
    "  --vocab_file=\"../config/vocab.txt\" `\n",
    "  --bert_config_file=\"../config/bert_config.json\" `\n",
    "  --max_seq_length=128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f023f9",
   "metadata": {},
   "source": [
    "**To get the contetnt of the new generated file use:**\n",
    "\n",
    "Get-Content \"bert/features_demo.jsonl\" -First 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
